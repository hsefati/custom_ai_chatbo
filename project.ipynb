{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9cb5ff",
   "metadata": {},
   "source": [
    "For implementation of a chatbot with the help foundation modeol like 'GPT-3.5-turbo-instruct', a database needed to able us to implement RAG.\n",
    "To this end, \"Character Description\" database is selected for the following:\n",
    "* Clear separation of data category\n",
    "* Clean Format\n",
    "* Contextually appropirate to create context for a prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec5f570",
   "metadata": {},
   "source": [
    "# Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "267d1aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai.embeddings_utils import get_embedding, distances_from_embeddings\n",
    "\n",
    "EMBEDDING_MODEL_NAME = \"text-embedding-ada-002\"\n",
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a595980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set opanai api key\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "openai.api_key = \"voc-3536329941266772997668678e47bca8fda1.32828252\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file from local path\n",
    "df = pd.read_csv(\"./data/character_descriptions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5efcb73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new 'text' column by combining all relevant columns\n",
    "df['text'] = df.apply(lambda row: f\"{row['Name']}: {row['Description']} This is a {row['Medium']} set in {row['Setting']}.\", axis=1)\n",
    "\n",
    "# Keep only the 'text' column\n",
    "df_transformed = df[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1e66ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transformed data to a new csv file\n",
    "df_transformed.to_csv(\"./data/character_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30549fd5",
   "metadata": {},
   "source": [
    "### Creating an Embeddings Index with `openai.Embedding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_costum_embedding(text):\n",
    "    response = openai.Embedding.create(\n",
    "        model=\"text-embedding-ada-002\",\n",
    "        input=text\n",
    "    )\n",
    "    return response[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26777/2047624594.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_transformed[\"embeddings\"] = df_transformed[\"text\"].apply(get_costum_embedding)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for each character description\n",
    "df_transformed[\"embeddings\"] = df_transformed[\"text\"].apply(get_costum_embedding)\n",
    "# Save embeddings for future use\n",
    "df_transformed.to_csv(\"./data/character_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385acd47",
   "metadata": {},
   "source": [
    "### Finding Relevant Data with Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c403f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows_sorted_by_relevance(prompt, df):   \n",
    "\t# Get embeddings for the prompt text\n",
    "\tprompt_embeddings = get_embedding(prompt, engine=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "\tdf_copy = df.copy()\n",
    "\tdf_copy[\"distances\"] = distances_from_embeddings(\n",
    "\t\t\tprompt_embeddings,\n",
    "\t\t\tdf_copy[\"embeddings\"].values,\n",
    "\t\t\tdistance_metric=\"cosine\"\n",
    "\t)\n",
    "\n",
    "\t# Sort the copied dataframe by the distances and return it\n",
    "\t# (shorter distance = more relevant so we sort in ascending order)\n",
    "\tdf_copy.sort_values(\"distances\", ascending=True, inplace=True)\n",
    "\treturn df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74280b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings from the csv file\n",
    "df_embedding = pd.read_csv(\"./data/character_embeddings.csv\")\n",
    "# Make sure the embeddings are in the correct format\n",
    "df_embedding[\"embeddings\"] = df_embedding[\"embeddings\"].apply(eval).apply(np.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc768d",
   "metadata": {},
   "source": [
    "### Tokenizing with `tiktoken` and compsoing a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ea03825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(question, df, max_token_count):\n",
    "    \"\"\"\n",
    "    Given a question and a dataframe containing rows of text and their\n",
    "    embeddings, return a text prompt to send to a Completion model\n",
    "    \"\"\"\n",
    "    # Create a tokenizer that is designed to align with our embeddings\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    # Count the number of tokens in the prompt template and question\n",
    "    prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the question\n",
    "can't be answered based on the context, say \"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    current_token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                            len(tokenizer.encode(question))\n",
    "\n",
    "    context = []\n",
    "    for text in get_rows_sorted_by_relevance(question, df)[\"text\"].values:\n",
    "\n",
    "        # Increase the counter based on the number of tokens in this row\n",
    "        text_token_count = len(tokenizer.encode(text))\n",
    "        current_token_count += text_token_count\n",
    "\n",
    "        # Add the row of text to the list if we haven't exceeded the max\n",
    "        if current_token_count <= max_token_count:\n",
    "            context.append(text)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return prompt_template.format(\"\\n\\n###\\n\\n\".join(context), question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e6d0c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(\n",
    "    question, df, max_prompt_tokens=2000, max_answer_tokens=500\n",
    "):\n",
    "    \"\"\"\n",
    "    Given a question, a dataframe containing rows of text, and a maximum\n",
    "    number of desired tokens in the prompt and response, return the\n",
    "    answer to the question according to an OpenAI Completion model\n",
    "\n",
    "    If the model produces an error, return an empty string\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = create_prompt(question, df, max_prompt_tokens)\n",
    "\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "            model=COMPLETION_MODEL_NAME,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_answer_tokens\n",
    "        )\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4901c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_answer = answer_question(\"who old is jack from england?\", df_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40s'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6f646989",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_answer = answer_question(\"Give me an acter from USA with Muscial medium?\", df_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Donna, Johnny, Dolly, Crystal, Karma, Sable, Olivia'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c6b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Jack is described as a middle-aged man in his 40s, a successful businessman, and Sarah's boss. He has a no-nonsense attitude and is fiercely loyal to his friends and family. He is married to Alice and the play is set in England.\n",
      "Chatbot: Donna could be considered an actor from USA with Musical medium as she is a seasoned performer on stage in a Musical set in USA.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    response = answer_question(user_input, df_embedding)\n",
    "    print(\"Chatbot:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a029d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
